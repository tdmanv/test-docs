.. _tutorial:

Tutorial
========

In this tutorial you'll deploy a simple application in Kubernetes. We'll then
incrementally use Kanister's features to manage the application's Data. 


.. contents:: Installation Overview
  :local:

Prerequisites
-------------

* kubernetes 1.7 or higher

* `kubectl <https://kubernetes.io/docs/tasks/tools/install-kubectl/>`_ installed
  and setup

* A running K10 controller. See :ref:`install` 

Example Application
-----------------

This tutorial begins by deploying our sample application. Our application is
contrived, but useful for demonstrating Kanister's features. Every Second, it
appends the current time to a log file. The image we deploy contains the aws
sdk.

.. code-block:: yaml

  $ cat <<EOF | kubectl create -f -
  apiVersion: apps/v1beta1
  kind: Deployment
  metadata:
    name: time-logger
  spec:
    replicas: 1
    template:
      metadata:
        labels:
          app: time-logger
     spec:
       containers:
       - name: test-container
         image: containerlabs/aws-sdk
         command: ["sh", "-c"]
         args: ["while true; do for x in $(seq 1200); do date >> /var/log/time.log; sleep 1; done; truncate /var/log/time.log --size 0; done"]
  EOF


Invoking Kanister Actions
--------------------

The first Kanister CustomResource we're going to deploy is a blueprint.
Blueprints are a set of instructions that tell the controller how to perform an
action. This blueprint has a single action called `backup`. The action `backup`
has a single phase named `backupToS3`. `backupToS3` invokes the Kanister
function `KubeExec`, which is similar to invoking `kubectl exec ...`. All
Kanister functions accept a list of strings as arguments. `KubeExec`'s first few
arguments specify which container to run in. The last arguments are the command
we're running.  In this case, we'll create a blueprint which will simply dump
the timelog to stdout.


Simple Blueprint
++++++++++++++++

.. code-block:: yaml

  $ cat <<EOF | kubectl create -f -
  apiVersion: cr.kanister.io/v1alpha1
  kind: Blueprint
  metadata:
    name: time-log-bp
  actions:
    backup:
      type: Deployment
      phases:
      - func: KubeExec
        name: backupToS3
        args:
        - "{{ .Deployment.Namespace }}"
        - "{{ index .Deployment.Pods 0 }}"
        - test-container
        - sh
        - -c
        - echo /var/log/time.log 
  EOF

.. todo:: 

  * Add reference to blueprints
    
  * Add glossary terms

    * Blueprint

    * Kansiter function

The next CustomResource we'll deploy is an ActionSet. An ActionSet is created
each time we want to execute any Kanister actions. The ActionSet contains all
the runtime information the controller needs during execution. It can contain
multiple Actions, each acting on a different Kubernetes object. The ActionSet
we're about to create in this tutorial specifes the time-logger Deployment we
created earlier and the backup action inside our Blueprint.

Simple ActionSet
++++++++++++++++

.. code-block:: yaml

  $ cat <<EOF | kubectl create -f -
  apiVersion: cr.kanister.io/v1alpha1
  kind: ActionSet
  metadata:
    generateName: s3backup-
  spec:
    actions:
    - name: backup
      blueprint: time-log-bp
      object:
        kind: Deployment
        name: time-logger
        namespace: default
  EOF

Get the Action's Status
+++++++++++++++++++++++

The controller will watch it's current namespace for any ActionSets we create.
Once it sees a new ActionSet, it will begin execution. Since our example is
pretty simple, it's probably done by the time you finished reading this. Let's
look at the updated status of the ActionSet and checkout the controller logs.

.. code-block:: bash

  # get the ActionSet status
  $ kubectl get actionsets.cr.kansiter.io -o yaml

  # check the controller log
  $ kubectl get pod -l app=kanister-operator


Consuming ConfigMaps
--------------------

Congrats on running your first Kanister action! You were able to get data out of
your time-logger, but if we want to really protect our time-logger's precious
data, we're going to need to add some configuration.  Kanister pulls
configuration from ConfigMaps. A reference to the ConfigMap is chosen in an
ActionSet, the controller fetches that ConfigMap and makes it available to
Blueprints through parameter templating.

In this section of the tutorial, we're going to use a ConfigMap to choose where
to backup our time log. We'll name our ConfigMap and consume it through
argument templating in the Blueprint. We'll map the name to a ConfigMap
reference in the ActionSet.

We create the ConfigMap with an S3 path where we'll eventually push our time
log. Please change the  path to something you have access to.

.. code-block:: yaml

  $ cat <<EOF | kubectl create -f -
  apiVersion: v1
  kind: ConfigMap
  metadata:
    name: s3-location
    data:
      path: s3://time-log-test-bucket/tutorial
  EOF

We modify the Blueprint to consume the path from the ConfigMap. We give it a
name `location` in the `configMapNames` section. We can access the values in the
map through Argument templating. For now we'll just print the path name to
stdout, but eventually we'll backp the time log to that path.

.. code-block:: yaml

   apiVersion: cr.kanister.io/v1alpha1
   kind: Blueprint
   metadata:
     name: time-log-bp
   actions:
     backup:
       type: Deployment
       configMapNames:
       - location
       phases:
       - func: KubeExec
         name: backupToS3
         args:
         - "{{ .Deployment.Namespace }}"
         - "{{ index .Deployment.Pods 0 }}"
         - test-container
         - sh
         - -c
         - |
           echo /var/log/time.log 
           echo "{{ .ConfigMaps.location.Data.path }}"

We create a new ActionSet that maps the name in the Blueprint, `location`, to
the ConfigMap we created earlier.

.. code-block:: yaml

  $ cat <<EOF | kubectl create -f -
  apiVersion: cr.kanister.io/v1alpha1
  kind: ActionSet
  metadata:
    generateName: s3backup-
  spec:
    actions:
    - name: backup
      blueprint: time-log-bp
      object:
        kind: Deployment
        name: time-logger
        namespace: default
      configMaps:
        location:
          name: s3-location
          namespace: default
  EOF

You can use the commands in XXX to check that the controller rendered the
values in the ConfigMap and they were successfully printed in the controller
log.

Consuming Secrets
----------------

In order for us to actually push the time log to s3, we'll need to get
credentials. In kubernetes, credentials are stored in secrets. Kanister supports
in the same way it supports ConfigMaps. The secret is named and rendered in the
blueprint. The name to reference mapping is created in the ActionSet. 

In our example, we'll need to use secrets to push the time log to S3.

.. warning::

  Secrets may contain sensitive information. It is up to the author of each
  blueprint to guarantee that secrets are not logged.

This step requires a bit of homework. You'll need to create aws credentials that
have read/write access to the bucket you specified in the ConfigMap. Fill them
in below and use kubectl to create the secret.

.. code-block:: yaml

  apiVersion: v1
  kind: Secret
  metadata:
    name: aws-creds
  type: Opaque
  data:
    aws_access_key_id: XXXX
    aws_secret_access_key: XXXX


Name the secret in the `secretNames` section. We can then consume it through
templates and assign it to bash variables. Because we now have access to the
bucket in the ConfigMap, we can also push the log to S3. In this Secret, we
store the credentials as binary data. We can use the templating engines
`toString` function, courtesy of sprig (TODO: Add reference).

.. code-block:: yaml

  apiVersion: cr.kanister.io/v1alpha1
  kind: Blueprint
  metadata:
    name: time-log-bp
  actions:
    backup:
      type: Deployment
      configMapNames:
      - location
      secretNames:
      - aws
      phases:
      - func: KubeExec
        name: backupToS3
        args:
        - "{{ .Deployment.Namespace }}"
        - "{{ index .Deployment.Pods 0 }}"
        - test-container
        - sh
        - -c
        - |
          AWS_ACCESS_KEY_ID={{ .Secrets.aws.Data.aws_access_key_id | toString }}         \
          AWS_SECRET_ACCESS_KEY={{ .Secrets.aws.Data.aws_secret_access_key | toString }} \
          aws s3 cp /var/log/time.log "{{ .ConfigMaps.location.Data.path }}"

We create an ActionSet that has the name to Secret reference under its `secrets`
field.

.. code-block:: yaml

  apiVersion: cr.kanister.io/v1alpha1
  kind: ActionSet
  metadata:
    generateName: s3backup-
  spec:
    actions:
    - name: backup
      blueprint: time-log-bp
      object:
        kind: Deployment
        name: time-logger
        namespace: default
      configMaps:
        location:
          name: s3-location
          namespace: default
      secrets:
        aws:
          name: aws-creds
          namespace: default


Artifacts
---------

We're pushing objects to S3 now, but we're not done yet. We now need to retrieve
the logs we've pushed to S3. Kanister provides an Artifact mechanism to track
and retrieve data we've externalized. Artifacts may be consumed or created
inside blueprints.

An Artifact is a set of key value pairs. it is up to us to put the required
information in Artifacts.


Output Artifacts
++++++++++++++++

Output artifacts are named and populated by blueprints. They are the only
template parameter that can be rendered using other template parameters. This
allows them to be configured based on ConfigMaps, Secrets and the current state
of the application. After a phase executes successfully, the rendered artifact
will be included in the ActionSet.

In our example, we'll create an outputArtifact called `timeLog` that contains
the full path of our data in S3. This path's base will be configured using a
ConfigMap. 

.. code-block:: yaml

  apiVersion: cr.kanister.io/v1alpha2
    kind: Blueprint
    metadata:
      name: time-log-bp
    actions:
      backup:
        type: Deployment
        configMapNames:
        - location
        secretNames:
        - aws
        outputArtifacts:
          timeLog:
            path: '{{ .ConfigMaps.location.Data.path }}/time-log/'
        phases:
          - func: KubeExec
            name: backupToS3
            args:
            - "{{ .Deployment.Namespace }}"
            - "{{ index .Deployment.Pods 0 }}"
            - test-container
            - sh
            - -c
            - |
              AWS_ACCESS_KEY_ID={{ .Secrets.aws.Data.aws_access_key_id | toString }}         \
              AWS_SECRET_ACCESS_KEY={{ .Secrets.aws.Data.aws_secret_access_key | toString }} \
              aws s3 cp /var/log/time.log "{{ .ArtifactsOut.timeLog.path }}"

If you re-execute this Kanister Action, you'll be able to see the Artifact in the
ActionSet status.

Input Artifacts
+++++++++++++++

Kanister can consume artifacts it creates using `inputArtifacts`. 
`inputArtifacts` are named in blueprints and are explit in the ActionSet.

In our example we'll restore an older time log. We've already stored the time
log in S3 and created an Artifact using the backup action. We'll now restore
that time log by using a new restore action.

We create a new ActionSet on our `time-logger` deployment with the action name
`restore`. This time we also include the full path in S3 as an Artifact.

.. code-block:: yaml

  apiVersion: cr.kanister.io/v1alpha1
  kind: ActionSet
  metadata:
    generateName: s3restore
  spec:
    actions:
      - name: restore
        blueprint: time-log-bp
        object:
          kind: Deployment
          name: time-logger
          namespace: default
        artifacts:
          timeLog:
            path: s3://time-log-test-bucket/tutorial/time.log

We add a restore action to the blueprint. This action does not need the
ConfigMap because the `inputArtifact` contains the fully specified path. 

.. code-block:: yaml

  apiVersion: cr.kanister.io/v1alpha1
  kind: Blueprint
  metadata:
    name: time-log-bp
  actions:
    backup:
  ...
    restore:
      type: Deployment
      secretNames:
      - aws
      inputArtifactNames:
      - timeLog
      phases:
      - func: KubeExec
        name: restoreFromS3
        args:
        - "{{ .Deployment.Namespace }}"
        - "{{ index .Deployment.Pods 0 }}"
        - test-container
        - sh
        - -c
        - |
          AWS_ACCESS_KEY_ID={{ .Secrets.aws.Data.aws_access_key_id | toString }}         \
          AWS_SECRET_ACCESS_KEY={{ .Secrets.aws.Data.aws_secret_access_key | toString }} \
          aws s3 cp "{{ .ArtifactsIn.timeLog.path }}" /var/log/time.log

We can check the controller logs to see that the time log was restored
successfully

.. note:: 

  We've omitted the backup action for brevity.

Time
----

.. todo:: 

  Include and example using time.
  '{{ .ConfigMaps.location.Data.path }}/time-log/{{ toDate "2006-01-02T15:04:05.999999999Z07:00" .Time  | date "2006-01-02" }}'


Using kanctl to Chain ActionSets
-------------

.. todo:: 

  Add an example on how to use kanctl

